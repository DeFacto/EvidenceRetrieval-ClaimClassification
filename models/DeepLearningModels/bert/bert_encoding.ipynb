{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Claims and Documents using BERT Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import jsonlines\n",
    "from bert_serving.client import BertClient\n",
    "# from keras.layers import Concatenate, Dense, LSTM, Input, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fever_binary > claim (65), sent(138) (done)\n",
    "# test_fever_binary > claim (27), sent(126) (done)\n",
    "\n",
    "# train_birth_place > claim (12), sent(493)\n",
    "# test_birth_place > claim (10), sent(712)\n",
    "\n",
    "# train_fever_3 > claim (65), sent (138) (done)\n",
    "# test_fever_3 > claim(19), sent (102)\n",
    "\n",
    "# train_fever_rej > claim (23), sent (128)\n",
    "# test_fever_rej > claim (17), sent (95)\n",
    "\n",
    "# train_fever_sup > claim (65), sent (138) (done)\n",
    "# test_fever_sup > claim (65), sent (102) (done)\n",
    "\n",
    "# train_institution > claim (16), sent (1140)\n",
    "# test_institution > claim (13), sent (494)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count  0\n",
      "(2, 256, 768)\n"
     ]
    }
   ],
   "source": [
    "bc = BertClient()\n",
    "\n",
    "claims = [\"Hello i am good \", \"Hey whats up\"]\n",
    "sents = [\"Hello i am good \", \"Hey whats up\"]\n",
    "\n",
    "                         \n",
    "sents_pair = [[claim+' ||| '+sent] for claim,sent in zip(claims,sents)]\n",
    "\n",
    "vec = np.empty((len(sents_pair), 768))\n",
    "\n",
    "count = 0\n",
    "for sent in sents_pair:\n",
    "    \n",
    "    if count == 0:\n",
    "        vec = bc.encode(sent)\n",
    "    else:\n",
    "        vec = np.vstack((vec, bc.encode(sent)))\n",
    "        \n",
    "    if count % 300 == 0:\n",
    "        print (\"count \", count)\n",
    "    count += 1\n",
    "\n",
    "print (vec.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.75344056,  0.79740226,  0.02449594, ...,  0.96724576,\n",
       "         -0.40242007,  0.16235533],\n",
       "        [ 0.20766653,  0.8428221 ,  0.8658044 , ...,  1.6331116 ,\n",
       "          0.24914826, -0.45936972],\n",
       "        [ 0.5816068 ,  0.01597154,  0.40155065, ...,  0.66567385,\n",
       "          0.181842  ,  0.16843253],\n",
       "        ...,\n",
       "        [ 0.        , -0.        , -0.        , ...,  0.        ,\n",
       "         -0.        ,  0.        ],\n",
       "        [ 0.        , -0.        , -0.        , ...,  0.        ,\n",
       "         -0.        ,  0.        ],\n",
       "        [ 0.        , -0.        , -0.        , ...,  0.        ,\n",
       "         -0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.19006939,  0.7364943 ,  0.04667989, ...,  0.82265013,\n",
       "          0.19136831,  0.08038574],\n",
       "        [-1.234218  ,  0.5487854 ,  0.9132608 , ...,  1.1474283 ,\n",
       "          0.5931537 , -0.31002355],\n",
       "        [ 0.67117476, -0.03327115,  0.5120853 , ...,  0.799096  ,\n",
       "          0.6229607 ,  0.3647747 ],\n",
       "        ...,\n",
       "        [ 0.        , -0.        , -0.        , ...,  0.        ,\n",
       "         -0.        ,  0.        ],\n",
       "        [ 0.        , -0.        , -0.        , ...,  0.        ,\n",
       "         -0.        ,  0.        ],\n",
       "        [ 0.        , -0.        , -0.        , ...,  0.        ,\n",
       "         -0.        ,  0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset_name = \"fever_full_binary_train\"\n",
    "\n",
    "# train_data = \"/home/kkuma12s/thesis/Proof_Extraction/data/fever-full/\"+dataset_name+\".jsonl\" \n",
    "\n",
    "train_data = \"/home/kkuma12s/thesis/Proof_Extraction/data/fever-full/complete_pipeline/sent_ret/fever_full_binary_dev_sent_ret.jsonl\"\n",
    "claims = []\n",
    "sents = []\n",
    "labels = []\n",
    "\n",
    "with jsonlines.open(train_data, mode='r') as f:\n",
    "    tmp_dict = {}\n",
    "    for example in f:\n",
    "        claims.append(example[\"claim\"])\n",
    "        sents.append(example[\"sentence\"])\n",
    "        labels.append(example[\"label\"])\n",
    "\n",
    "    tmp_dict = {'claim':claims, 'sentence':sents, 'label':labels}\n",
    "    train_data = pd.DataFrame(data=tmp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158018, 3)\n"
     ]
    }
   ],
   "source": [
    "print (train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soul Food is a 1997 American comedy-drama film produced by Kenneth `` Babyface '' Edmonds , Tracey Edmonds and Robert Teitel and released by Fox 2000 Pictures . Robert Teitel Robert Teitel comedy-drama film comedy-drama film Tracey Edmonds Tracey Edmonds Fox 2000 Pictures Fox 2000 Pictures\n",
      "\n",
      "\n",
      "Featuring an ensemble cast , the film stars Vanessa L. Williams , Vivica A. Fox , Nia Long , Michael Beach , Mekhi Phifer , Jeffrey D. Sams , Irma P. Hall , Gina Ravera and Brandon Hammond . Brandon Hammond Brandon Hammond Vanessa L. Williams Vanessa L. Williams Vivica A. Fox Vivica A. Fox Nia Long Nia Long Michael Beach Michael Beach Mekhi Phifer Mekhi Phifer Jeffrey D. Sams Jeffrey D. Sams Irma P. Hall Irma P. Hall Gina Ravera Gina Ravera ensemble cast ensemble cast\n",
      "\n",
      "\n",
      "For the 2010 United States Census , people counted as `` Hispanic '' or `` Latino '' were those who identified as one of the specific Hispanic or Latino categories listed on the census questionnaire  (  `` Mexican , '' `` Puerto Rican , '' or `` Cuban ''  )  as well as those who indicated that they were `` other Spanish , Hispanic , or Latino . '' Spanish Spain Hispanic Hispanic Latino Latino (demonym) 2010 United States Census 2010 United States Census Puerto Rican Puerto Ricans Mexican Mexican people Cuban Cubans\n",
      "\n",
      "\n",
      "The national origins classified as Hispanic or Latino by the United States Census Bureau are the following : Spanish , Argentine , Cuban , Colombian , Puerto Rican , Mexican , Dominican , Costa Rican , Guatemalan , Honduran , Nicaraguan , Panamanian , Salvadoran , Bolivian , Chilean , Ecuadorian , Paraguayan , Peruvian , Uruguayan , and Venezuelan . Spanish Spain Hispanic Hispanic Latino Latino (demonym) United States Census Bureau United States Census Bureau Argentine Argentina Puerto Rican Puerto Ricans Mexican Mexican people Dominican People of the Dominican Republic Honduran Honduras Salvadoran Salvadoran Cuban Cubans Guatemalan Demographics of Guatemala Colombian Colombian people\n",
      "\n",
      "\n",
      "For her performance as Mathison , Claire Danes has received several major acting awards , including the Primetime Emmy Award for Outstanding Lead Actress in a Drama Series , the Golden Globe Award for Best Actress -- Television Series Drama , the Screen Actors Guild Award for Outstanding Performance by a Female Actor in a Drama Series , the Satellite Award for Best Actress -- Television Series Drama , and the TCA Award for Individual Achievement in Drama . Claire Danes Claire Danes Primetime Emmy Award for Outstanding Lead Actress in a Drama Series Primetime Emmy Award for Outstanding Lead Actress in a Drama Series Screen Actors Guild Award for Outstanding Performance by a Female Actor in a Drama Series Screen Actors Guild Award for Outstanding Performance by a Female Actor in a Drama Series TCA Award for Individual Achievement in Drama TCA Award for Individual Achievement in Drama\n",
      "\n",
      "\n",
      "Roth 's other notable films include Captives  (  1994  )  , Little Odessa  (  1994  )  , Everyone Says I Love You  (  1996  )  , Gridlock 'd  (  1997  )  , Deceiver  (  1997  )  , Legend of 1900  (  1999  )  , Planet of the Apes  (  2001  )  , Invincible  (  2001  )  , Funny Games  (  2007  )  , The Incredible Hulk  (  2008  )  , Arbitrage  (  2012  )  , Broken  (  2012  )  , Selma  (  2014  )  and 600 Miles  (  2016  )  . Captives Captives Little Odessa Little Odessa (film) Everyone Says I Love You Everyone Says I Love You Deceiver Deceiver (film) Legend of 1900 Legend of 1900 Planet of the Apes Planet of the Apes (2001 film) Invincible Invincible (2001 drama film) Funny Games Funny Games (2007 film) The Incredible Hulk The Incredible Hulk (film) Arbitrage Arbitrage (film) Broken Broken (2012 film) Selma Selma (film) 600 Miles 600 Miles\n",
      "\n",
      "\n",
      "Unlike most European sporting supporters groups -- often concentrated around their own club 's city of origin -- , it is widespread throughout the Apennine Peninsula and abroad , mainly in countries with a significant presence of Italian immigrants , making Juventus a symbol of campanilismo  (  `` Anti-parochialism ''  )  and italianit√†  (  `` Italianness ''  )  along with the club 's tradition of success , some of which have had a significant impact in Italian society , especially in the 1930s and the first post-war decade , as well as the ideological politics and socio-economic origin of the club 's sympathisers and the club 's contribution to the national team -- the most for an Italian club -- , uninterrupted since the second half of the 1920s and recognised as one of the most influential in international football , having performed a decisive role in the Azzurri 's World Cup triumphs of 1934 , 1982 and 2006 . Italian Football in Italy club List of football clubs in Italy the first Timeline of association football#1980s Apennine Peninsula Italian Peninsula Italian immigrants Italian diaspora post-war post-war ideological Political spectrum politics Politics in Italy socio-economic origin Social class in Italy contribution Juventus F.C. and the Italian national football team national team Italy national football team international football Association football#International competitions World Cup FIFA World Cup 1934 1934 FIFA World Cup 1982 1982 FIFA World Cup 2006 2006 FIFA World Cup\n",
      "\n",
      "\n",
      "The series follows a group of teens : Clarke Griffin  (  Eliza Taylor  )  , Bellamy Blake  (  Bob Morley  )  , Octavia Blake  (  Marie Avgeropoulos  )  , Jasper Jordan  (  Devon Bostick  )  , Monty Green  (  Christopher Larkin  )  , Raven Reyes  (  Lindsey Morgan  )  , Finn Collins  (  Thomas McDonell  )  , John Murphy  (  Richard Harmon  )  , and Wells Jaha  (  Eli Goree  )  as they are among the first people from a space habitat , `` The Ark '' , to return to Earth after a devastating nuclear apocalypse ; the series also focuses on Dr. Abby Griffin  (  Paige Turco  )  , Clarke 's mother ; Marcus Kane  (  Henry Ian Cusick  )  , a council member on the Ark ; and Thelonious Jaha  (  Isaiah Washington  )  , the Chancellor of the Ark and Wells ' father . Eliza Taylor Eliza Taylor Paige Turco Paige Turco Thomas McDonell Thomas McDonell Eli Goree Eli Goree Bob Morley Bob Morley Marie Avgeropoulos Marie Avgeropoulos Christopher Larkin Christopher Larkin (actor) Devon Bostick Devon Bostick Isaiah Washington Isaiah Washington Henry Ian Cusick Henry Ian Cusick Lindsey Morgan Lindsey Morgan Richard Harmon Richard Harmon space habitat space habitat nuclear apocalypse Nuclear holocaust\n",
      "\n",
      "\n",
      "Her films Mystic Pizza  (  1988  )  , Steel Magnolias  (  1989  )  Sleeping with the Enemy  (  1991  )  , Hook  (  1991  )  , The Pelican Brief  (  1993  )  , My Best Friend 's Wedding  (  1997  )  , Conspiracy Theory  (  1997  )  , Notting Hill  (  1999  )  , Runaway Bride  (  1999  )  , Ocean 's Eleven  (  2001  )  , Mona Lisa Smile  (  2003  )  , Ocean 's Twelve  (  2004  )  , Charlie Wilson 's War  (  2007  )  , Valentine 's Day  (  2010  )  , Eat Pray Love  (  2010  )  , Mirror Mirror  (  2012  )  , and Money Monster  (  2016  )  have collectively brought box office receipts of over US$ 2.7 billion , making her one of the most successful actresses in terms of box office receipts . Mystic Pizza Mystic Pizza Steel Magnolias Steel Magnolias Sleeping with the Enemy Sleeping with the Enemy Hook Hook (film) The Pelican Brief The Pelican Brief (film) Conspiracy Theory Conspiracy Theory (film) Notting Hill Notting Hill (film) Runaway Bride Runaway Bride (film) Mona Lisa Smile Mona Lisa Smile Eat Pray Love Eat Pray Love Mirror Mirror Mirror Mirror (film) Money Monster Money Monster\n",
      "\n",
      "\n",
      "The Times is the first newspaper to have borne that name , lending it to numerous other papers around the world , including The Times of India  (  founded in 1838  )  , The Straits Times  (  Singapore  )   (  1845  )  , The New York Times  (  1851  )  , The Irish Times  (  1859  )  , Le Temps  (  France  )   (  1861-1942  )  , the Cape Times  (  South Africa  )   (  1872  )  , the Los Angeles Times  (  1881  )  , the Trenton Times  (  1882  )  , The Seattle Times  (  1891  )  , The Manila Times  (  1898  )  , The Daily Times  (  Malawi  )   (  1900  )  , El Tiempo  (  Colombia  )   (  1911  )  , The Canberra Times  (  1926  )  , Times of Malta  (  1935  )  , and The Washington Times  (  1982  )  . The Times of India The Times of India The Straits Times The Straits Times The New York Times The New York Times The Irish Times The Irish Times Le Temps Le Temps (Paris) Cape Times Cape Times Los Angeles Times Los Angeles Times Trenton Times Trenton Times The Seattle Times The Seattle Times The Manila Times The Manila Times The Daily Times The Daily Times (Malawi) El Tiempo El Tiempo (Colombia) The Canberra Times The Canberra Times Times of Malta Times of Malta The Washington Times The Washington Times\n",
      "\n",
      "\n",
      "Some of his most popular Hindi film songs are `` Channa Mereya '' , `` Tum Hi Ho '' , `` Phir Bhi Tumko Chahunga '' , `` Aayat '' , `` Raabta '' , `` Ae Dil Hai Mushkil '' , `` Muskurane ki wajah '' , `` Laal Ishq '' , `` Kabhi Jo Baadal Barse '' , `` Samjhawan '' , `` Suno Na Sangemarmar '' , `` Ilahi '' , `` Sooraj Dooba Hain '' , `` Sanam Re '' , `` Soch Na Sake '' , `` Mast Magan '' , `` Bolna '' , `` Sawan Aaya Hai '' , `` Gerua '' , `` Janam Janam '' , `` Nashe Si Chadh Gayi '' , `` Khamoshiyan '' , `` Hamari Adhuri Kahani '' , `` Enna Sona '' , `` Dilliwaali Girlfriend '' , `` Palat '' , `` Dharkhaast '' , `` Naina '' , `` Kabira '' , `` Zaalima '' , `` Yeh Ishq Hai '' , `` Alvida '' . Hindi Hindi language Tum Hi Ho Tum Hi Ho Muskurane ki wajah Muskurane Sooraj Dooba Hain Sooraj Dooba Hain Ae Dil Hai Mushkil Ae Dil Hai Mushkil#Soundtrack Channa Mereya Channa Mereya Phir Bhi Tumko Chahunga Phir Bhi Tumko Chahunga Aayat Aayat (song) Raabta Raabta (song) Laal Ishq Laal Ishq Kabhi Jo Baadal Barse Kabhi Jo Baadal Barse Samjhawan Samjhawan Suno Na Sangemarmar Suno Na Sangemarmar Ilahi Ilahi Sanam Re Sanam Re#Soundtrack Soch Na Sake Soch Na Sake Mast Magan Mast Magan Bolna Bolna (Song) Sawan Aaya Hai Sawan Aaya Hai Gerua Dilwale (2015 film)#Soundtrack Janam Janam Dilwale (2015 film)#Soundtrack Nashe Si Chadh Gayi Nashe Si Chadh Gayi Khamoshiyan Khamoshiyan#Soundtrack Hamari Adhuri Kahani Hamari Adhuri Kahani#Soundtrack Enna Sona Ok Jaanu#Soundtrack Dilliwaali Girlfriend Dilliwaali Girlfriend Palat Palat ‚Äì Tera Hero Idhar Hai Dharkhaast Shivaay#Soundtrack Naina Naina (song) Kabira Kabira (song) Zaalima Raees (film)#Soundtrack Yeh Ishq Hai Rangoon (2017 Hindi film)#Soundtrack Alvida Rangoon (2017 Hindi film)#Soundtrack\n",
      "\n",
      "\n",
      "They composed soundtracks for many films , including Aashiqui  (  1990  )  , Saajan  (  1991  )  , Deewana  (  1992  )  , Dil Ka Kya Kasoor  (  1992  )  , Hum Hain Rahi Pyar Ke  (  1993  )  , Rang  (  1993  )  , Dilwale  (  1994  )  , Raja  (  1995  )  , Barsaat  (  1995  )  , Agni Sakshi  (  1996  )  , Jeet  (  1996  )  , Raja Hindustani  (  1996  )  , Pardes  (  1997  )  , Sirf Tum  (  1999  )  , Dhadkan  (  2000  )  , Kasoor  (  2001  )  , Hum Ho Gaye Aapke  (  2001  )  , Raaz  (  2002  )  , Dil Hai Tumhaara  (  2002  )  , Dil Ka Rishta  (  2003  )  , Andaaz  (  2003  )  , Tumsa Nahi Dekha  (  2004  )  , Bewafaa  (  2005  )  and many others . Aashiqui Aashiqui Saajan Saajan Deewana Deewana (1992 film) Dil Ka Kya Kasoor Dil Ka Kya Kasoor Hum Hain Rahi Pyar Ke Hum Hain Rahi Pyar Ke Rang Rang Dilwale Dilwale (1994 film) Raja Raja (1995 film) Barsaat Barsaat (1995 film) Agni Sakshi Agni Sakshi (1996 film) Jeet Jeet (1996 film) Raja Hindustani Raja Hindustani Pardes Pardes (film) Sirf Tum Sirf Tum Dhadkan Dhadkan Kasoor Kasoor Hum Ho Gaye Aapke Hum Ho Gaye Aapke Raaz Raaz (2002 film) Dil Hai Tumhaara Dil Hai Tumhaara Dil Ka Rishta Dil Ka Rishta Andaaz Andaaz Tumsa Nahi Dekha Tumsa Nahin Dekha (2004 film) Bewafaa Bewafaa (2005 film)\n",
      "\n",
      "\n",
      "max length  340\n"
     ]
    }
   ],
   "source": [
    "claims = train_data[\"claim\"].tolist()\n",
    "sents = train_data[\"sentence\"].tolist()\n",
    "# print (claims[0])\n",
    "# print (len(claims[0].split(\" \")))\n",
    "max_length = 0\n",
    "\n",
    "for i in range(len(sents)):\n",
    "    if max_length < len(sents[i].split(\" \")):\n",
    "        max_length = len(sents[i].split(\" \"))\n",
    "        print (sents[i])\n",
    "        print (\"\\n\")\n",
    "\n",
    "print (\"max length \", max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-20-0213fee84325>, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-0213fee84325>\"\u001b[0;36m, line \u001b[0;32m44\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# len(train_df[\"sentence\"])\n",
    "\n",
    "# 80k + 80k\n",
    "# bc = BertClient()\n",
    "\n",
    "\n",
    "                         \n",
    "# sents_pair = [[claim+' ||| '+sent] for claim,sent in zip(claims[:80000],sents[:80000])]\n",
    "\n",
    "# vec = np.empty((len(sents_pair), 768))\n",
    "\n",
    "# count = 0\n",
    "# for sent in sents_pair:\n",
    "    \n",
    "#     if count == 0:\n",
    "#         vec = bc.encode(sent)\n",
    "#     else:\n",
    "#         vec = np.vstack((vec, bc.encode(sent)))\n",
    "        \n",
    "#     if count % 300 == 0:\n",
    "#         print (\"count \", count)\n",
    "#     count += 1\n",
    "\n",
    "# print (vec.shape)\n",
    "\n",
    "# print (\"saving vector into zip\")\n",
    "\n",
    "# file_name = \"./new_embeddings/fever_full_dev_binary_sent_ret_bert_80\"\n",
    "\n",
    "# def save_dataset_and_compress(dataset_dict, name):\n",
    "#     with gzip.GzipFile(name + '.pgz', 'w') as f:\n",
    "#         pickle.dump(dataset_dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "# save_dataset_and_compress(vec, file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pickle.dump(vec[:8000,:], open(\"./new_embeddings/fever_full_train_binary_bert_embeddings_1.pkl\", \"wb\"))\n",
    "# import gzip\n",
    "# def save_dataset_and_compress(dataset_dict, name):\n",
    "#     with gzip.GzipFile(name + '.pgz', 'w') as f:\n",
    "#         pickle.dump(dataset_dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "# save_dataset_and_compress(vec, \"./new_embeddings/fever_full_train_binary_bert_embeddings_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22005, 256, 768)\n"
     ]
    }
   ],
   "source": [
    "print (vec.shape)\n",
    "# part1 = pickle.load(open(\"./new_embeddings/train_fever_bin_combinedEmbed_multiling1.pkl\", \"rb\"))\n",
    "# part2 = pickle.load(open(\"./new_embeddings/train_fever_bin_combinedEmbed_multiling2.pkl\", \"rb\"))\n",
    "\n",
    "# combine = np.concatenate((part1, part2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_compressed_pickle_file(pickle_file_name):\n",
    "    with gzip.open(pickle_file_name+\".pgz\", 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "result = load_compressed_pickle_file(\"./new_embeddings/fever_full_train_binary_bert_embeddings_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22005, 256, 768)\n"
     ]
    }
   ],
   "source": [
    "print (result.shape)\n",
    "# vec111 = np.empty((5, 2))\n",
    "# print (vec111)\n",
    "# print (vec111[:4,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7570, 256, 768)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
